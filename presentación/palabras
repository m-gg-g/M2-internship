FIRST PART!!

In this presentation I will talk about what we have done in my M2 internship. In it we explored two examples of percolation games on $\Z^2$, whose limit values turn out to be directly related to percolation through specific lattice structures that provide strategic advantages to the players. We geometrically characterize these structures, analyze the critical probabilities of their occurrence, and explore their strategic implications. The use of computational simulations offered additional insights.

Secondly, we extend the percolation game model by incorporating a stochastic process into the state transitions. For these generalized games, we prove a result similar to one already known for percolation games.

In this presentation, I will focus on one of the two examples and briefly present the generalized model along with a sketch of a proof of our main result.

Our game is played in Z^2, with i.i.d. Bernoulli costs assigned to the edges. To the configuration space of costs, we associate the sigma-algebra generated by events depending on finitely many edges, and for p between 0 and 1, we let P_p denote the corresponding product measure.  

In essence, given a realization of the costs and a token initially placed at a vertex of Z^2, the game proceeds in stages as follows: At each stage, player 1 moves the token either up or down. Then, knowing player 1's action, player 2 moves the token either left or right. Player 1 receives the payoff associated with the edges traversed by the token, while player 2 receives the opposite amount. Is a zero-sum game. Player 1 aims to maximize the payoff, while player 2 aims to minimize it.

The n-stage game the total payoff is the random average payoff over n stages. The value, which is also random, has been proven to exist and is equal to the maxmin or minmax of the total payoff function. For the infinite-stage game, or simply the game, the total payoff is defined as the limit superior of the average payoff. It is also a known result that, defined in this way, the game has a value, equal to this.

Knowing that it exist, does it depend on z? Is it random? Regarding these questions we prove the following: v_p(z) is independent of z and is almost surely deterministic. 

Given that v_p is constant, a natural question is: What is its value? 
And what should we focus on to answer this question? 
We focus on lattice structures that confer advantages to the players.

These structures are essentially infinite lattice graphs where one player has a strategy to keep the token within the structure, regardless of the other player's actions.

For instance, consider this portion of a structure. If the game is at this point and player 2 plays right, player 1 will respond by moving up. Conversely, if player 2 plays left, player 1 will move down. A similar analysis can be applied to the remaining points not on the boundaries. 

Further imagine, is filled with 1s. Since player 1 aims to maximize, this is advantageous for him. He can guarantee a payoff of 1. Therefore, if such a structure filled with 1s exists, since the player 1 can reach it in a ?nite number of steps, the value of the game is 1.

We formally defined structures in which each player can capture the other and refer to them as winning structures. Here is the definition for player 1.

As the game is symmetric, until the end of the game analysis, we will focus solely on Player 1. 

From this definition it follows easily that an infinite subgraph of Z^2 is a winning structure for player 1 if and only if, around any of its vertices, one of the following local configurations is present. We further define 41-horizontal structures as winning structures for player 1 that are filled with 1s, H sub 41 the event of their existence, and q_1 their critical probability.

With all these definitions in place, we can state as a theorem the discussion I did in terms of the graphs, that is, if the Bernoulli parameter is greater than q_1, then the value of the game is 1. For this result to be meaningful, it is fundamental to establish that the critical probability is non-trivial.

To prove this, first note that since the game is symmetric and v_p is non-decreasing, it is sufficient to prove that q_1 < 1. To establish this, we will focus on a subset of 41-horizontal structures for which it is easier to determine the bound on their critical probability.

These structures, that we call 41^* are 41-horizontal structures oriented in such a way that they can be traversed without retracing steps or encountering squares without lateral neighbors. In other words, we want to avoid these kind of structures, which I think are unnecessarily more complicated.

For these subset of structures, we similarly define the event of their existence and their critical probability.

Since these structures are a subset of 41-horizontal structures, the theorem now reduces to proving that the critical probability of these structures is less than 1. To achieve this, we use a Peierls-type argument and the fact that a path of squares translates into a path of 1-dependent sites, this is done by associating each square to it center and making the center open if and only the square has all it edges with cost equal to 1. We do not provide the details of this proof here due to its length and because we find it more beneficial to focus on the results.

Therefore, we have this theorem that we have mentioned before where q_1 is non-trivial. Motivated by a result established for the other game, which we will not discuss here, we further conjecture that the value is 1 if and only if the Bernoulli parameter is greater than or equal than q_1.

The supercritical regime is covered by this theorem, so, we have it. In the subcritical regime, we think it will be feasible to consider a suboptimal strategy for player 2 that ensures a path with a positive density of 0s. And the critical regime, as always, is the more challenging. Establishing results for this regime would require studying the critical behavior of percolation through the winning structures that we have seen. However, we have not found references to this type of structure in the literature, and proving this is not straightforward, so we leave it as a task for future work.

When we began studying these games, we considered simulating them to test our hypotheses and gain additional insights into their values. What we discovered for this one is particularly interesting! 

What we have until now is this. This indicates two phase transitions in the value of the game. However, through simulations, we discovered additional phase transitions where the distribution of 0 and 1 costs across the winning structures emerged as a significant factor.

In this computational analysis, we started by estimating the expected value of v_n as a function of p. To do this, we followed the next approach: We fixed a finite two-dimensional lattice and a sequence of equally spaced p and for each of them, we ran 30 simulations with i.i.d. realizations of the costs and for each fixed realization, we computed the value of the largest finite stage game starting at the center, using a recursive method. 

Here is a representation of the recursion for a lattice of size 8.

The idea is that the value of the n-stage game starting from a particular state depends on the values of (n-1)-stage games starting from other states. For example, from this position, the value of the two-stage game depends on the values of the one-stage games starting from these four surrounding points.

From these simulations, we observe that the value stabilizes at 0, 0.25, 0.5, 0.75 and 1, indicating eight phase transitions. Where the red and green points represent estimates of the probability thresholds between which v_p is almost surely equal to x, for x one of these 5 values.

We might expect that these thresholds correspond to the critical probabilities for some specific structures! In particular, we should have that this red point, which is an estimate of r_1, is equal to q_1.

We conjecture that these probability thresholds r_x correspond to the critical probabilities of winning structures for player 1 conformed by squares with k 1s, which we call k-squares. We are saying, for instance, that the value is greater or equal to 0.25 if and only if, a winning structure for player 1 conformed by squares with k or more 1s exists. Is this OK?

Through the simulation of the game, we have obtained estimations for the left-hand side and now aim to estimate the right-hand side.

To do this, instead of studying the critical probability for these events directly, we focus on their restricted events, which correspond to * winning structures. Remember, structures that resemble this one, not this one. At this stage of the analysis, the game is no longer consider. Instead, we focus on the percolation model on Z^2 and aim to identify * clusters conformed by k-squares that span the finite lattice from the left side to the right side.

To achieve this, we employ a modified version of the Newman-Ziff algorithm that identifies the onset of percolation, where paths formed by k-squares that meet the desired conditions appear.

Using the data obtained from this algorithm, we generate these graphs where we display the critical probability as a function of the size of the lattice for the four values of k. We found that the range of values aligns quite well with the values of the red points in the previous graphs, which confirms our expectations.

In summary: given a value of p, v_p is constant and its value depends on the regime in which winning structures appear, formed by squares containing 0, 1, 2, 3 or 4 ones.

SECOND PART!!

This game that we have just seen is a specific example of percolation games introduced in 2023 by Garnier and Ziliotto, where two players move a token along Z^d.

This games can be described by a tuple Gamma, where: 
I and J are finite sets representing respectively players action sets. 
E is a probability space with transformations tau_z that shift the space in a way that preserves probabilities and form a group under composition. These transformations are further assumed to be ergodic.
g is the payoff function which is random, and is assumed to be uniformly bounded and stationary.
and q is the transition function, that depends on the player's actions and determine the transition between states.

For a given realization of the payoffs and an initial state, the game proceed as follows:
The players observes the entire realization, and at each stage n:
Player 1 chooses an action. Then knowing this action, player 2 chooses their action. Then, player 1 then receives the corresponding payoff based on the current state and actions, and player 2 receives the opposite payoff. The token then moves to the next state according to the transition function. Finally, the actions just taken and the new state are publicly announced.

For the n-stage game the payoff is the random average payoff over n stages, and the value is the corresponding maxmin of this payoff. 

A central question in this model is whether the n-stage value converges to a limit value.
It has been proven that for i.i.d. and oriented percolation games, the value's sequence converges almost surely to a constant value as the duration tends to infinity. 

Here, ``oriented'' involves the transition function and refers to games where the token tends to move in a fixed direction regardless of players' actions
And ``i.i.d.'' indicates that the payoff function is i.i.d.

In the second part of our work, we extend this model by introducing a random stochastic process into the game's transition function, where kxi_m are i.i.d. random variables defined in calligraphic E.

Since this generalization does not touch the payoff function, as long as Gamma is i.i.d. Gamma_ksi remains i.i.d. On the other hand, if the original game Gamma is oriented, this modification allowed the token to return to previously visited states. However, if ksi_m has zero expectation for all m, Gamma_ksi will still be oriented in expectation.

Our main result for this generalized game is the extension of the previously established result for the original game. Specifically, we prove that the n-stage value of the Gamma_mu game coming from an oriented and i.i.d. game Gamma converges to a constant as the duration tends to infinity, and establish the same rate of convergence of its expectation to this value.

For proving this result, we follow the same steps as in the proof of the original one. 

1-First, we prove that the n-stage value concentrates around its expectation. 
2-Next, we show that its expectation converges to a constant.
3-Then, we establish the convergence rate.
4- and finally, using the previously established results, we prove that v_n concentrates around v_infinity as n tends to infinity.

The only part of the proof that required reconsideration for the generalized model was the first step, and this is the part for which I will provide a sketch.

To prove this point, it must be shown that this probability decreases with n. To achieve this, we rely on Azumaâ€“Hoeffding's inequality.

To prove this, first, we define calligraphic C as the discrete cube in which the n-stage game, starting from the origin, stays in. Recall that the game Gamma is oriented, meaning there is a vector u which indicates the direction followed by the token. For this vector, we define the orthogonal hyperplane, and note that this cube can be covered by a collection of discrete hyperplanes that are translations of H.

After this, for each r, is establish a martingale structure by defining the sigma-algebra containing information about the payoffs in the portion of the space up to and including the r-th hyperplane, and by defining the martingale W_r. To apply the concentration inequality, we need bounded differences, which is established by this inequality.

To prove this inequality, for each r, its further define an auxiliary game that coincides with Gamma_\mu except for the payoff function, which is 0 on the corresponding hyperplane.

Because Gamma is oriented, without the fluctuations that random increments bring, regardless of player's strategies, the token would be in the hyperplane at most once. For Gamma_mu, the token still tends to move in the direction of u, but its progress will be slower since it can backtrack and pass through previously visited hyperplanes. The number of times this occurs up to stage n is defined as M_n. Therefore, there can be at most M_n + 1 stages where the state lies in this hyperplane. Thus, by the definition of the payoff function and the auxiliary game follows this inequality.

This inequality is the difference from the original proof. As we have just mentioned, without the fluctuations introduced by random increments, the token would be in the hyperplane at most once, which leads to this other inequality, but in our case, the token can return, and the number of times it does so is represented by M_n. Hence, this inequality arises.

To transition from this left-hand side to this one, we first express it in terms of the value, take the conditional expectation, and apply Jensen's inequality. Therefore, to make this transition from this right hand side to this one, it is sufficient to prove that M_n is bounded by a constant.

And this is what we proved, given a pair of strategies for both players and an initial state, the expected number of returns to an already visited hyperplane is bounded by a constant, that is, is big O of 1. Where this expectation is with respect to the probability distribution over the set of plays induced by an initial state, a pair of strategies and the stochastic process.

To prove this, we first expressed the total magnitude of the displacement in the direction u from a given hyperplane as the sum of the vector projections of the stage transitions onto u. Next, note that for the token to cross the hyperplane again, the random component, given by the cumulative effect of ksi, must at least overcome this distance. By applying Hoeffding inequality to the stochastic process ksi and summing over this probabilities, we draw our claim.

And this concludes what I aim to present. With this result, we have bounded differences for our martingale, allowing us to apply the concentration inequality and obtain the concentration of v_n on it expected value.

